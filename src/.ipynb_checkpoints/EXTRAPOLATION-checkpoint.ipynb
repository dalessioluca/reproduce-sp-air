{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRAPOLATION sp-air \n",
    "Recall to select the myenv in the python kernel\n",
    "\"source activate myenv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.12 | packaged by conda-forge | (default, Dec  9 2020, 00:36:02) \n",
      "[GCC 9.3.0]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import copy\n",
    "import numpy\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imresize\n",
    "\n",
    "import config\n",
    "import model\n",
    "import rat_spn\n",
    "from visualize import draw_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_file(train_file, test_file, out_of_sample_test_file):\n",
    "    loaded_train = numpy.load(train_file)\n",
    "    loaded_test = numpy.load(test_file)\n",
    "    loaded_test_out = numpy.load(out_of_sample_test_file)\n",
    "    return (loaded_train['images'], \n",
    "            loaded_train['counts']), (loaded_test['images'], \n",
    "                                      loaded_test['counts']), (loaded_test_out['images'], \n",
    "                                                               loaded_test_out['counts'])\n",
    "\n",
    "class SpnReconstructor:\n",
    "    def __init__(self, spn):\n",
    "        self.spn = spn\n",
    "        self.input_ph = tf.placeholder(tf.float32, (1, spn.num_dims))\n",
    "        self.marginalized = tf.placeholder(tf.float32, (1, spn.num_dims))\n",
    "        self.spn_out = spn.forward(self.input_ph, self.marginalized)\n",
    "        self.max_idx_tensors = {}\n",
    "        for layer in spn.vector_list:\n",
    "            for vector in layer:\n",
    "                if isinstance(vector, rat_spn.SumVector):\n",
    "                    self.max_idx_tensors[vector.name] = vector.max_child_idx\n",
    "\n",
    "    def reconstruct(self, image, marginalized, sess, sample=False):\n",
    "        original_shape = image.shape\n",
    "        image = np.reshape(image, (1, -1))\n",
    "        marginalized = np.reshape(marginalized, (1, -1))\n",
    "        feed_dict = {self.input_ph: image, self.marginalized: marginalized}\n",
    "        max_idxs = sess.run(self.max_idx_tensors, feed_dict=feed_dict)\n",
    "        recon = self.spn.reconstruct(max_idxs, sess, sample)\n",
    "        recon = recon * (1 - marginalized)\n",
    "        recon = np.clip(recon, 0.0, 1.0)\n",
    "        return np.reshape(recon, original_shape)\n",
    "\n",
    "\n",
    "class SupairTrainer:\n",
    "    def __init__(self, conf):\n",
    "        \n",
    "        \n",
    "        # load data and add make sure that conf has the appropriate variables describing the dataset\n",
    "        bboxes = None\n",
    "        if conf.dataset == 'MNIST':\n",
    "            (x, counts), (x_test, c_test), (x_test_out, c_test_out) = load_dataset_from_file(conf.train_file,\n",
    "                                                                                             conf.test_file,\n",
    "                                                                                             conf.out_test_file)\n",
    "            conf.scene_width = x.shape[-3]\n",
    "            conf.scene_height = x.shape[-2]\n",
    "            conf.channels = x.shape[-1]\n",
    "        else:\n",
    "            raise ValueError('unknown dataset', conf.dataset)\n",
    "            \n",
    "        # shuffle the order\n",
    "        shuffle = numpy.random.permutation(x.shape[0])\n",
    "        self.x, self.counts = x[shuffle,...], counts[shuffle]\n",
    "        shuffle = numpy.random.permutation(x_test.shape[0])\n",
    "        self.x_test, self.c_test = x_test[shuffle,...], c_test[shuffle]\n",
    "        shuffle = numpy.random.permutation(x_test_out.shape[0])\n",
    "        self.x_test_out, self.c_test_out = x_test_out[shuffle,...], c_test_out[shuffle]\n",
    "            \n",
    "            \n",
    "        \n",
    "        self.conf = conf\n",
    "\n",
    "        # determine and create result dir\n",
    "        i = 1\n",
    "        log_path = conf.result_path + 'run0'\n",
    "        while os.path.exists(log_path):\n",
    "            log_path = '{}run{}'.format(conf.result_path, i)\n",
    "            i += 1\n",
    "        os.makedirs(log_path)\n",
    "        self.log_path = log_path\n",
    "\n",
    "        if not os.path.exists(conf.checkpoint_dir):\n",
    "            os.makedirs(conf.checkpoint_dir)\n",
    "\n",
    "        input_shape = [conf.batch_size, conf.scene_width, conf.scene_height, conf.channels]\n",
    "        # build model\n",
    "        with tf.device(conf.device):\n",
    "            self.mdl = model.Supair(conf)\n",
    "            self.in_ph = tf.placeholder(tf.float32, input_shape)\n",
    "            self.elbo = self.mdl.elbo(self.in_ph)\n",
    "\n",
    "            self.mdl.num_parameters()\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer()\n",
    "            self.train_op = self.optimizer.minimize(-1 * self.elbo)\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.saver = tf.train.Saver()\n",
    "        if self.conf.load_params:\n",
    "            resume_ckpt = os.path.join(self.conf.path_to_ckpt)\n",
    "            self.saver.restore(self.sess, resume_ckpt)\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            self.sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        print('Built model')\n",
    "        self.obj_reconstructor = SpnReconstructor(self.mdl.obj_spn)\n",
    "        self.bg_reconstructor = SpnReconstructor(self.mdl.bg_spn)\n",
    "\n",
    "        tfgraph = tf.get_default_graph()\n",
    "        self.tensors_of_interest = {\n",
    "            'z_where': tfgraph.get_tensor_by_name('z_where:0'),\n",
    "            'z_pres': tfgraph.get_tensor_by_name('z_pres:0'),\n",
    "            'bg_score': tfgraph.get_tensor_by_name('bg_score:0'),\n",
    "            'y': tfgraph.get_tensor_by_name('y:0'),\n",
    "            'obj_vis': tfgraph.get_tensor_by_name('obj_vis:0'),\n",
    "            'bg_maps': tfgraph.get_tensor_by_name('bg_maps:0')\n",
    "        }\n",
    "\n",
    "    def log_and_print_progress(self, n_iter, acc, elbo, avg_obj, log_file, title):\n",
    "        print('{}, N_iter {}, Accuracy: {}, avg_obj: {}, elbo {}'.format(title, n_iter, acc, avg_obj, elbo))\n",
    "        log_file.write('{}, {}, {}, {}, {}\\n'.format(title, n_iter, acc, avg_obj, elbo))\n",
    "        log_file.flush()\n",
    "\n",
    "    def reconstruct_scenes(self, images, cur_values, draw_boxes=True):\n",
    "        num_detected = np.sum(np.rint(cur_values['z_pres']), axis=1).astype(np.int32)\n",
    "        results = []\n",
    "        for i in range(images.shape[0]):\n",
    "            n = int(num_detected[i])\n",
    "            y = cur_values['y'][i]\n",
    "            z_where = cur_values['z_where'][i]\n",
    "            obj_vis = cur_values['obj_vis'][i]\n",
    "            objects = [self.obj_reconstructor.reconstruct(y[k], 1 - obj_vis[k], self.sess)\n",
    "                       for k in range(n)]\n",
    "            bg_map = cur_values['bg_maps'][i, n]\n",
    "            bg = self.bg_reconstructor.reconstruct(images[i], 1 - bg_map, self.sess, sample=True)\n",
    "            \n",
    "            for j in range(n - 1, -1, -1):\n",
    "                col = int(z_where[j, 2])\n",
    "                row = int(z_where[j, 5])\n",
    "                w = int(z_where[j, 0] * self.conf.patch_width)\n",
    "                h = int(z_where[j, 4] * self.conf.patch_height)\n",
    "                \n",
    "                # check for pathological object dimensions; treat as not present\n",
    "                if h <= 0 or w <= 0 or row < 0 or col < 0 or row + h > 50 or col + w > 50:\n",
    "                    continue\n",
    "                obj = imresize(np.squeeze(objects[j]), (h, w)).astype(np.float32) / 255.0\n",
    "                bg[row:row + h, col:col + w, 0] = obj\n",
    "\n",
    "            results.append(bg)\n",
    "\n",
    "        results = np.stack(results, 0)\n",
    "        results = np.clip(results, 0.0, 1.0)\n",
    "        \n",
    "        # Now Add the bounding boxes\n",
    "        if draw_boxes:\n",
    "            boxes = draw_images(results[...,0], cur_values['z_where'], cur_values['z_pres'], window_size=self.conf.patch_width, text=None)\n",
    "            boxes = numpy.moveaxis(boxes, -3, -1) / 255.0\n",
    "            return boxes + (boxes==0)*results  # this should work b/c broadcasting\n",
    "        else:\n",
    "            return results\n",
    "            \n",
    "\n",
    "    def run_training(self):\n",
    "        batch_size = self.conf.batch_size\n",
    "        batches_per_epoch = self.x.shape[0] // batch_size\n",
    "        sess = self.sess\n",
    "\n",
    "        perf_log = open(self.conf.log_file, 'a')\n",
    "        \n",
    "        for n_iter in range(20000):\n",
    "            i = n_iter % batches_per_epoch            \n",
    "            batch = self.x[i * batch_size: (i + 1) * batch_size]\n",
    "            \n",
    "            # print(\"DEBUG ->\",n_iter, i, batch.shape)\n",
    "                 \n",
    "            _, cur_elbo, cur_values = sess.run([self.train_op, self.elbo, self.tensors_of_interest], feed_dict={self.in_ph: batch})\n",
    "\n",
    "            if (n_iter % 1000 ==0) and (n_iter > 0):\n",
    "                # save the model \n",
    "                ckpt_file = os.path.join(self.conf.checkpoint_dir, \"model_\"+str(n_iter)+\".ckpt\")\n",
    "                self.saver.save(sess, ckpt_file)\n",
    "                \n",
    "            if (n_iter % 100 == 0):\n",
    "                # train accuracy\n",
    "                num_detected = np.sum(np.rint(cur_values['z_pres']), axis=1).astype(np.int32)\n",
    "                batch_counts = self.counts[i * batch_size: (i + 1) * batch_size]\n",
    "                train_acc = np.mean(num_detected == batch_counts)\n",
    "                avg_obj = np.average(num_detected)\n",
    "                self.log_and_print_progress(n_iter, train_acc, cur_elbo, avg_obj, perf_log, title=\"train\")\n",
    "                    \n",
    "            if (n_iter % 100 == 0):\n",
    "                print(\"computing test acc\")\n",
    "                test_elbo = 0\n",
    "                test_acc, test_avg_obj = self.compute_test_acc(kind=\"in\")\n",
    "                self.log_and_print_progress(n_iter, test_acc, test_elbo, test_avg_obj, perf_log, title=\"test_in\")\n",
    "                test_acc, test_avg_obj = self.compute_test_acc(kind=\"out\")\n",
    "                self.log_and_print_progress(n_iter, test_acc, test_elbo, test_avg_obj, perf_log, title=\"test_out\")\n",
    "     \n",
    "        perf_log.close()\n",
    "\n",
    "\n",
    "    def compute_test_acc(self, kind):\n",
    "        batch_size = self.conf.batch_size\n",
    "        \n",
    "        if kind == \"in\":\n",
    "            num_batches = self.x_test.shape[0] // batch_size \n",
    "        elif kind == \"out\":\n",
    "            num_batches = self.x_test_out.shape[0] // batch_size \n",
    "        else:\n",
    "            raise ValueError('unknown kind', kind)\n",
    "            \n",
    "        z_pres = self.tensors_of_interest['z_pres']\n",
    "        correct, num_detected_tot = 0, 0\n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            if kind == \"in\":\n",
    "                x_batch = self.x_test[i * batch_size: (i + 1) * batch_size]\n",
    "                c_batch = self.c_test[i * batch_size: (i + 1) * batch_size]\n",
    "            elif kind == \"out\":\n",
    "                x_batch = self.x_test_out[i * batch_size: (i + 1) * batch_size]\n",
    "                c_batch = self.c_test_out[i * batch_size: (i + 1) * batch_size]\n",
    "            else:\n",
    "                raise ValueError('unknown kind', kind)\n",
    "\n",
    "            cur_pres = self.sess.run(z_pres, feed_dict={self.in_ph: x_batch})\n",
    "            num_detected = np.sum(np.rint(cur_pres), axis=1)\n",
    "            correct += np.sum(num_detected == c_batch)\n",
    "            num_detected_tot += np.sum(num_detected)\n",
    "        test_acc = correct / (num_batches * batch_size)\n",
    "        avg_obj = num_detected_tot / (num_batches * batch_size)\n",
    "        return test_acc, avg_obj\n",
    "    \n",
    "    \n",
    "def grid_images(images, ncol=8, figsize=(12, 8)):\n",
    "    nrow = int(numpy.ceil(float(images.shape[0]) / ncol))\n",
    "    RGB = (3 == images.shape[-1])\n",
    "    \n",
    "    if nrow > 1:\n",
    "        fig, ax = plt.subplots(ncols=ncol, nrows=nrow, figsize=figsize)\n",
    "        for i in range(images.shape[0]):\n",
    "            c,r = i % ncol, i // ncol\n",
    "            if RGB:\n",
    "                ax[r,c].imshow(images[i,...], vmin=0, vmax=1)\n",
    "            else:\n",
    "                ax[r,c].imshow(images[i,...,0], cmap='gray', vmin=0, vmax=1)\n",
    "                \n",
    "            ax[r,c].set_axis_off()\n",
    "    else:\n",
    "        fig, ax = plt.subplots(ncols=images.shape[0], nrows=1, figsize=figsize)\n",
    "        for i in range(images.shape[0]):\n",
    "            if RGB:\n",
    "                ax[i].imshow(images[i,...], vmin=0, vmax=1)\n",
    "            else:\n",
    "                ax[i].imshow(images[i,...,0], cmap='gray', vmin=0, vmax=1)\n",
    "            ax[i].set_axis_off()\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def sub_select_inference(mask, cur_values):\n",
    "    return {'z_where' : cur_values['z_where'][mask,...],\n",
    "            'z_pres' : cur_values['z_pres'][mask,...],\n",
    "            'bg_score' : cur_values['bg_score'][mask,...],\n",
    "            'y' : cur_values['y'][mask,...],\n",
    "            'obj_vis' : cur_values['obj_vis'][mask,...],\n",
    "            'bg_maps' : cur_values['bg_maps'][mask,...],\n",
    "            }\n",
    "\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = config.SupairConfig()\n",
    "conf.visual = False\n",
    "\n",
    "# data config\n",
    "conf.dataset = 'MNIST'  # select dataset from 'MNIST', 'sprites', 'omniglot'\n",
    "conf.patch_width = conf.patch_height = 28\n",
    "\n",
    "conf.noise = False  # add Gaussian noise\n",
    "conf.structured_noise = True  # add background grid\n",
    "conf.background_model = True  # use learned background model\n",
    "\n",
    "conf.num_steps = 6  # maximum number of digits\n",
    "conf.dataset = 'MNIST'  # select MNIST\n",
    "\n",
    "# learning config\n",
    "conf.load_params = False\n",
    "conf.save_params = True\n",
    "conf.batch_size = 64 # default is 256\n",
    "\n",
    "\n",
    "# ORIGINAL\n",
    "conf.train_file = '../processed_dataset/their_mnist_train.npz'\n",
    "conf.test_file = '../processed_dataset/their_mnist_test.npz'\n",
    "conf.out_test_file = '../processed_dataset/their_mnist_test.npz'\n",
    "conf.checkpoint_dir = 'checkpoints_original'\n",
    "conf.log_file = 'reproduce.csv'\n",
    "conf.dir_result = 'REPRODUCE'\n",
    "conf.min_obj_scale = 0.3  # bounds for width of bounding box relative to native width=28\n",
    "conf.max_obj_scale = 0.9  # bounds for width of bounding box relative to native width=28\n",
    "\n",
    "## EXTRAPOLATION NO GRID\n",
    "#conf.train_file = '../processed_dataset/mnist_train_80x80_n0_3_no_grid.npz'\n",
    "#conf.test_file = '../processed_dataset/mnist_test_80x80_n0_3_no_grid.npz'\n",
    "#conf.out_test_file = '../processed_dataset/mnist_test_80x80_n4_6_no_grid.npz'\n",
    "#conf.checkpoint_dir = 'checkpoints_no_grid'\n",
    "#conf.log_file = 'no_grid.csv'\n",
    "#conf.dir_result = 'EXTRAPOLATION_NO_GRID'\n",
    "#conf.min_obj_scale = 0.3  # bounds for width of bounding box relative to native width=28\n",
    "#conf.max_obj_scale = 1.5  # bounds for width of bounding box relative to native width=28\n",
    "    \n",
    "# EXTRAPOLATION WITH GRID\n",
    "#conf.train_file = '../processed_dataset/mnist_train_80x80_n0_3_with_grid.npz'\n",
    "#conf.test_file = '../processed_dataset/mnist_test_80x80_n0_3_with_grid.npz'\n",
    "#conf.out_test_file = '../processed_dataset/mnist_test_80x80_n4_6_with_grid.npz'\n",
    "#conf.checkpoint_dir = 'checkpoints_with_grid'\n",
    "#conf.log_file = 'with_grid.csv'\n",
    "#conf.dir_result = 'EXTRAPOLATION_WITH_GRID'\n",
    "#conf.min_obj_scale = 0.3  # bounds for width of bounding box relative to native width=28\n",
    "#conf.max_obj_scale = 1.5  # bounds for width of bounding box relative to native width=28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert their dataset in our format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x, counts), (x_test, c_test) = datasets.load_mnist(conf.scene_width, max_digits=2, path=conf.data_path)\n",
    "#\n",
    "#numpy.savez_compressed(\"their_mnist_train\", images=x, counts=counts)\n",
    "#numpy.savez_compressed(\"their_mnist_test\", images=x_test, counts=c_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 50, 50, 1) (10000, 50, 50, 1) (10000, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, c_train), (x_test, c_test), (x_test_out, c_test_out)= load_dataset_from_file(conf.train_file,\n",
    "                                                                                       conf.test_file,\n",
    "                                                                                       conf.out_test_file)\n",
    "print(x_train.shape, x_test.shape, x_test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 2 0 0 2 1 2 2 2 2 0 2 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 16 Axes>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(c_train[0:16])\n",
    "grid_images(x_train[0:16], figsize=(12,3))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters:\n",
      "rnn 2836477\n",
      "obj-spn 286560\n",
      "bg-spn 90108\n",
      "TOTAL 3213145\n",
      "Built model\n",
      "train, N_iter 0, Accuracy: 0.359375, avg_obj: 0.03125, elbo 537.6937255859375\n",
      "computing test acc\n",
      "test_in, N_iter 0, Accuracy: 0.3359375, avg_obj: 0.0, elbo 0\n",
      "test_out, N_iter 0, Accuracy: 0.33643830128205127, avg_obj: 0.0, elbo 0\n",
      "train, N_iter 100, Accuracy: 0.4375, avg_obj: 0.0, elbo 972.9161987304688\n",
      "computing test acc\n",
      "test_in, N_iter 100, Accuracy: 0.3359375, avg_obj: 0.0, elbo 0\n",
      "test_out, N_iter 100, Accuracy: 0.33643830128205127, avg_obj: 0.0, elbo 0\n",
      "train, N_iter 200, Accuracy: 0.6875, avg_obj: 0.546875, elbo 1089.6165771484375\n",
      "computing test acc\n",
      "test_in, N_iter 200, Accuracy: 0.5802283653846154, avg_obj: 0.5608974358974359, elbo 0\n",
      "test_out, N_iter 200, Accuracy: 0.5809294871794872, avg_obj: 0.5603966346153846, elbo 0\n",
      "train, N_iter 300, Accuracy: 0.65625, avg_obj: 0.578125, elbo 1167.45556640625\n",
      "computing test acc\n",
      "test_in, N_iter 300, Accuracy: 0.6329126602564102, avg_obj: 0.6340144230769231, elbo 0\n",
      "test_out, N_iter 300, Accuracy: 0.6334134615384616, avg_obj: 0.6334134615384616, elbo 0\n",
      "train, N_iter 400, Accuracy: 0.71875, avg_obj: 0.65625, elbo 1255.000244140625\n",
      "computing test acc\n",
      "test_in, N_iter 400, Accuracy: 0.6629607371794872, avg_obj: 0.6657652243589743, elbo 0\n",
      "test_out, N_iter 400, Accuracy: 0.6635616987179487, avg_obj: 0.6652644230769231, elbo 0\n",
      "train, N_iter 500, Accuracy: 0.765625, avg_obj: 0.703125, elbo 1368.243896484375\n",
      "computing test acc\n",
      "test_in, N_iter 500, Accuracy: 0.7083333333333334, avg_obj: 0.7132411858974359, elbo 0\n",
      "test_out, N_iter 500, Accuracy: 0.7087339743589743, avg_obj: 0.7125400641025641, elbo 0\n",
      "train, N_iter 600, Accuracy: 0.875, avg_obj: 0.90625, elbo 1474.000732421875\n",
      "computing test acc\n",
      "test_in, N_iter 600, Accuracy: 0.8839142628205128, avg_obj: 0.9291866987179487, elbo 0\n",
      "test_out, N_iter 600, Accuracy: 0.8842147435897436, avg_obj: 0.9283854166666666, elbo 0\n",
      "train, N_iter 700, Accuracy: 0.90625, avg_obj: 1.09375, elbo 1540.379150390625\n",
      "computing test acc\n",
      "test_in, N_iter 700, Accuracy: 0.9349959935897436, avg_obj: 0.9607371794871795, elbo 0\n",
      "test_out, N_iter 700, Accuracy: 0.9351963141025641, avg_obj: 0.9598357371794872, elbo 0\n",
      "train, N_iter 800, Accuracy: 0.9375, avg_obj: 1.03125, elbo 1695.27783203125\n",
      "computing test acc\n",
      "test_in, N_iter 800, Accuracy: 0.9525240384615384, avg_obj: 1.007411858974359, elbo 0\n",
      "test_out, N_iter 800, Accuracy: 0.9525240384615384, avg_obj: 1.0063100961538463, elbo 0\n",
      "train, N_iter 900, Accuracy: 0.953125, avg_obj: 1.078125, elbo 1734.306396484375\n",
      "computing test acc\n",
      "test_in, N_iter 900, Accuracy: 0.9605368589743589, avg_obj: 0.9787660256410257, elbo 0\n",
      "test_out, N_iter 900, Accuracy: 0.9607371794871795, avg_obj: 0.9778645833333334, elbo 0\n",
      "train, N_iter 1000, Accuracy: 0.9375, avg_obj: 0.9375, elbo 1911.5648193359375\n",
      "computing test acc\n",
      "test_in, N_iter 1000, Accuracy: 0.965645032051282, avg_obj: 0.9930889423076923, elbo 0\n",
      "test_out, N_iter 1000, Accuracy: 0.9657451923076923, avg_obj: 0.9920873397435898, elbo 0\n",
      "train, N_iter 1100, Accuracy: 0.96875, avg_obj: 0.9375, elbo 1998.515869140625\n",
      "computing test acc\n",
      "test_in, N_iter 1100, Accuracy: 0.9709535256410257, avg_obj: 0.9864783653846154, elbo 0\n",
      "test_out, N_iter 1100, Accuracy: 0.9711538461538461, avg_obj: 0.9855769230769231, elbo 0\n",
      "train, N_iter 1200, Accuracy: 0.984375, avg_obj: 1.09375, elbo 2062.83203125\n",
      "computing test acc\n",
      "test_in, N_iter 1200, Accuracy: 0.9755608974358975, avg_obj: 0.9956931089743589, elbo 0\n",
      "test_out, N_iter 1200, Accuracy: 0.9755608974358975, avg_obj: 0.9945913461538461, elbo 0\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "trainer = SupairTrainer(conf)\n",
    "trainer.run_training()\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = numpy.zeros(conf.batch_size, dtype=numpy.bool)\n",
    "mask[25:30]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_values_train = sub_select_inference(mask, trainer.sess.run(trainer.tensors_of_interest, feed_dict={trainer.in_ph: x_train[:conf.batch_size]}))\n",
    "cur_values_test = sub_select_inference(mask, trainer.sess.run(trainer.tensors_of_interest, feed_dict={trainer.in_ph: x_test[:conf.batch_size]}))\n",
    "cur_values_test_out = sub_select_inference(mask, trainer.sess.run(trainer.tensors_of_interest, feed_dict={trainer.in_ph: x_test_out[:conf.batch_size]}))\n",
    "\n",
    "img_train = x_train[:conf.batch_size][mask]\n",
    "img_test = x_test[:conf.batch_size][mask]\n",
    "img_test_out = x_test_out[:conf.batch_size][mask]\n",
    "\n",
    "label_train = c_train[:conf.batch_size][mask]\n",
    "label_test = c_test[:conf.batch_size][mask]\n",
    "label_test_out = c_test_out[:conf.batch_size][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obj_train = np.sum((cur_values_train['z_pres'] > 0.5), axis=-1)\n",
    "n_obj_test = np.sum((cur_values_test['z_pres'] > 0.5), axis=-1)\n",
    "n_obj_test_out = np.sum((cur_values_test_out['z_pres'] > 0.5), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = trainer.reconstruct_scenes(img_train, cur_values_train, draw_boxes=True)\n",
    "results_test = trainer.reconstruct_scenes(img_test, cur_values_test, draw_boxes=True)\n",
    "results_test_out = trainer.reconstruct_scenes(img_test_out, cur_values_test_out, draw_boxes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(cur_values_train, conf.dir_result+\"/cur_values_train\",)\n",
    "save_obj(cur_values_test, conf.dir_result+\"/cur_values_test\")\n",
    "save_obj(cur_values_test_out, conf.dir_result+\"/cur_values_test_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(img_train[:conf.batch_size], conf.dir_result+\"/imgs_train\",)\n",
    "save_obj(img_test[:conf.batch_size], conf.dir_result+\"/imgs_test\")\n",
    "save_obj(img_test_out[:conf.batch_size], conf.dir_result+\"/imgs_test_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_train)\n",
    "b = grid_images(img_train, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_in_train.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_obj_train)\n",
    "b = grid_images(results_train, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_out_train.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_test)\n",
    "b = grid_images(img_test, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_in_test.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_obj_test)\n",
    "b = grid_images(results_test, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_out_test.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_test_out)\n",
    "b = grid_images(img_test_out, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_in_extrapolation.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_values_test_out[\"z_pres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_obj_test_out)\n",
    "b = grid_images(results_test_out, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_out_extrapolation.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu90.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu90:m59"
  },
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
