{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRAPOLATION sp-air \n",
    "Recall to select the myenv in the python kernel\n",
    "\"source activate myenv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.12 | packaged by conda-forge | (default, Dec  9 2020, 00:36:02) \n",
      "[GCC 9.3.0]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/myenv/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/REPO/reproduce-sp-air/src/visualize.py:12: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  matplotlib.use('Agg')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import copy\n",
    "import numpy\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imresize\n",
    "\n",
    "import config\n",
    "import model\n",
    "import rat_spn\n",
    "from visualize import draw_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_file(train_file, test_file, out_of_sample_test_file):\n",
    "    loaded_train = numpy.load(train_file)\n",
    "    loaded_test = numpy.load(test_file)\n",
    "    loaded_test_out = numpy.load(out_of_sample_test_file)\n",
    "    return (loaded_train['images'], \n",
    "            loaded_train['counts']), (loaded_test['images'], \n",
    "                                      loaded_test['counts']), (loaded_test_out['images'], \n",
    "                                                               loaded_test_out['counts'])\n",
    "\n",
    "class SpnReconstructor:\n",
    "    def __init__(self, spn):\n",
    "        self.spn = spn\n",
    "        self.input_ph = tf.placeholder(tf.float32, (1, spn.num_dims))\n",
    "        self.marginalized = tf.placeholder(tf.float32, (1, spn.num_dims))\n",
    "        self.spn_out = spn.forward(self.input_ph, self.marginalized)\n",
    "        self.max_idx_tensors = {}\n",
    "        for layer in spn.vector_list:\n",
    "            for vector in layer:\n",
    "                if isinstance(vector, rat_spn.SumVector):\n",
    "                    self.max_idx_tensors[vector.name] = vector.max_child_idx\n",
    "\n",
    "    def reconstruct(self, image, marginalized, sess, sample=False):\n",
    "        original_shape = image.shape\n",
    "        image = np.reshape(image, (1, -1))\n",
    "        marginalized = np.reshape(marginalized, (1, -1))\n",
    "        feed_dict = {self.input_ph: image, self.marginalized: marginalized}\n",
    "        max_idxs = sess.run(self.max_idx_tensors, feed_dict=feed_dict)\n",
    "        recon = self.spn.reconstruct(max_idxs, sess, sample)\n",
    "        recon = recon * (1 - marginalized)\n",
    "        recon = np.clip(recon, 0.0, 1.0)\n",
    "        return np.reshape(recon, original_shape)\n",
    "\n",
    "\n",
    "class SupairTrainer:\n",
    "    def __init__(self, conf):\n",
    "        \n",
    "        \n",
    "        # load data and add make sure that conf has the appropriate variables describing the dataset\n",
    "        bboxes = None\n",
    "        if conf.dataset == 'MNIST':\n",
    "            (x, counts), (x_test, c_test), (x_test_out, c_test_out) = load_dataset_from_file(conf.train_file,\n",
    "                                                                                             conf.test_file,\n",
    "                                                                                             conf.out_test_file)\n",
    "            conf.scene_width = x.shape[-3]\n",
    "            conf.scene_height = x.shape[-2]\n",
    "            conf.channels = x.shape[-1]\n",
    "        else:\n",
    "            raise ValueError('unknown dataset', conf.dataset)\n",
    "            \n",
    "        # shuffle the order\n",
    "        shuffle = numpy.random.permutation(x.shape[0])\n",
    "        self.x, self.counts = x[shuffle,...], counts[shuffle]\n",
    "        shuffle = numpy.random.permutation(x_test.shape[0])\n",
    "        self.x_test, self.c_test = x_test[shuffle,...], c_test[shuffle]\n",
    "        shuffle = numpy.random.permutation(x_test_out.shape[0])\n",
    "        self.x_test_out, self.c_test_out = x_test_out[shuffle,...], c_test_out[shuffle]\n",
    "            \n",
    "            \n",
    "        \n",
    "        self.conf = conf\n",
    "\n",
    "        # determine and create result dir\n",
    "        i = 1\n",
    "        log_path = conf.result_path + 'run0'\n",
    "        while os.path.exists(log_path):\n",
    "            log_path = '{}run{}'.format(conf.result_path, i)\n",
    "            i += 1\n",
    "        os.makedirs(log_path)\n",
    "        self.log_path = log_path\n",
    "\n",
    "        if not os.path.exists(conf.checkpoint_dir):\n",
    "            os.makedirs(conf.checkpoint_dir)\n",
    "\n",
    "        input_shape = [conf.batch_size, conf.scene_width, conf.scene_height, conf.channels]\n",
    "        # build model\n",
    "        with tf.device(conf.device):\n",
    "            self.mdl = model.Supair(conf)\n",
    "            self.in_ph = tf.placeholder(tf.float32, input_shape)\n",
    "            self.elbo = self.mdl.elbo(self.in_ph)\n",
    "\n",
    "            self.mdl.num_parameters()\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer()\n",
    "            self.train_op = self.optimizer.minimize(-1 * self.elbo)\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.saver = tf.train.Saver()\n",
    "        if self.conf.load_params:\n",
    "            resume_ckpt = os.path.join(self.conf.path_to_ckpt)\n",
    "            self.saver.restore(self.sess, resume_ckpt)\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            self.sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        print('Built model')\n",
    "        self.obj_reconstructor = SpnReconstructor(self.mdl.obj_spn)\n",
    "        self.bg_reconstructor = SpnReconstructor(self.mdl.bg_spn)\n",
    "\n",
    "        tfgraph = tf.get_default_graph()\n",
    "        self.tensors_of_interest = {\n",
    "            'z_where': tfgraph.get_tensor_by_name('z_where:0'),\n",
    "            'z_pres': tfgraph.get_tensor_by_name('z_pres:0'),\n",
    "            'bg_score': tfgraph.get_tensor_by_name('bg_score:0'),\n",
    "            'y': tfgraph.get_tensor_by_name('y:0'),\n",
    "            'obj_vis': tfgraph.get_tensor_by_name('obj_vis:0'),\n",
    "            'bg_maps': tfgraph.get_tensor_by_name('bg_maps:0')\n",
    "        }\n",
    "\n",
    "    def log_and_print_progress(self, n_iter, acc, elbo, avg_obj, log_file, title):\n",
    "        print('{}, N_iter {}, Accuracy: {}, avg_obj: {}, elbo {}'.format(title, n_iter, acc, avg_obj, elbo))\n",
    "        log_file.write('{}, {}, {}, {}, {}\\n'.format(title, n_iter, acc, avg_obj, elbo))\n",
    "        log_file.flush()\n",
    "\n",
    "    def reconstruct_scenes(self, images, cur_values, draw_boxes=True):\n",
    "        num_detected = np.sum(np.rint(cur_values['z_pres']), axis=1).astype(np.int32)\n",
    "        results = []\n",
    "        for i in range(images.shape[0]):\n",
    "            n = int(num_detected[i])\n",
    "            y = cur_values['y'][i]\n",
    "            z_where = cur_values['z_where'][i]\n",
    "            obj_vis = cur_values['obj_vis'][i]\n",
    "            objects = [self.obj_reconstructor.reconstruct(y[k], 1 - obj_vis[k], self.sess)\n",
    "                       for k in range(n)]\n",
    "            bg_map = cur_values['bg_maps'][i, n]\n",
    "            bg = self.bg_reconstructor.reconstruct(images[i], 1 - bg_map, self.sess, sample=True)\n",
    "            \n",
    "            for j in range(n - 1, -1, -1):\n",
    "                col = int(z_where[j, 2])\n",
    "                row = int(z_where[j, 5])\n",
    "                w = int(z_where[j, 0] * self.conf.patch_width)\n",
    "                h = int(z_where[j, 4] * self.conf.patch_height)\n",
    "                \n",
    "                # check for pathological object dimensions; treat as not present\n",
    "                if h <= 0 or w <= 0 or row < 0 or col < 0 or row + h > 50 or col + w > 50:\n",
    "                    continue\n",
    "                obj = imresize(np.squeeze(objects[j]), (h, w)).astype(np.float32) / 255.0\n",
    "                bg[row:row + h, col:col + w, 0] = obj\n",
    "\n",
    "            results.append(bg)\n",
    "\n",
    "        results = np.stack(results, 0)\n",
    "        results = np.clip(results, 0.0, 1.0)\n",
    "        \n",
    "        # Now Add the bounding boxes\n",
    "        if draw_boxes:\n",
    "            boxes = draw_images(results[...,0], cur_values['z_where'], cur_values['z_pres'], window_size=self.conf.patch_width, text=None)\n",
    "            boxes = numpy.moveaxis(boxes, -3, -1) / 255.0\n",
    "            return boxes + (boxes==0)*results  # this should work b/c broadcasting\n",
    "        else:\n",
    "            return results\n",
    "            \n",
    "\n",
    "    def run_training(self):\n",
    "        batch_size = self.conf.batch_size\n",
    "        batches_per_epoch = self.x.shape[0] // batch_size\n",
    "        sess = self.sess\n",
    "\n",
    "        perf_log = open(self.conf.log_file, 'a')\n",
    "        \n",
    "        for n_iter in range(20000):\n",
    "            i = n_iter % batches_per_epoch            \n",
    "            batch = self.x[i * batch_size: (i + 1) * batch_size]\n",
    "            \n",
    "            # print(\"DEBUG ->\",n_iter, i, batch.shape)\n",
    "                 \n",
    "            _, cur_elbo, cur_values = sess.run([self.train_op, self.elbo, self.tensors_of_interest], feed_dict={self.in_ph: batch})\n",
    "\n",
    "            if (n_iter % 1000 ==0) and (n_iter > 0):\n",
    "                # save the model \n",
    "                ckpt_file = os.path.join(self.conf.checkpoint_dir, \"model_\"+str(n_iter)+\".ckpt\")\n",
    "                self.saver.save(sess, ckpt_file)\n",
    "                \n",
    "            if (n_iter % 100 == 0):\n",
    "                # train accuracy\n",
    "                num_detected = np.sum(np.rint(cur_values['z_pres']), axis=1).astype(np.int32)\n",
    "                batch_counts = self.counts[i * batch_size: (i + 1) * batch_size]\n",
    "                train_acc = np.mean(num_detected == batch_counts)\n",
    "                avg_obj = np.average(num_detected)\n",
    "                self.log_and_print_progress(n_iter, train_acc, cur_elbo, avg_obj, perf_log, title=\"train\")\n",
    "                    \n",
    "            if (n_iter % 100 == 0):\n",
    "                print(\"computing test acc\")\n",
    "                test_elbo = 0\n",
    "                test_acc, test_avg_obj = self.compute_test_acc(kind=\"in\")\n",
    "                self.log_and_print_progress(n_iter, test_acc, test_elbo, test_avg_obj, perf_log, title=\"test_in\")\n",
    "                test_acc, test_avg_obj = self.compute_test_acc(kind=\"out\")\n",
    "                self.log_and_print_progress(n_iter, test_acc, test_elbo, test_avg_obj, perf_log, title=\"test_out\")\n",
    "     \n",
    "        perf_log.close()\n",
    "\n",
    "\n",
    "    def compute_test_acc(self, kind):\n",
    "        batch_size = self.conf.batch_size\n",
    "        \n",
    "        if kind == \"in\":\n",
    "            num_batches = self.x_test.shape[0] // batch_size \n",
    "        elif kind == \"out\":\n",
    "            num_batches = self.x_test_out.shape[0] // batch_size \n",
    "        else:\n",
    "            raise ValueError('unknown kind', kind)\n",
    "            \n",
    "        z_pres = self.tensors_of_interest['z_pres']\n",
    "        correct, num_detected_tot = 0, 0\n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            if kind == \"in\":\n",
    "                x_batch = self.x_test[i * batch_size: (i + 1) * batch_size]\n",
    "                c_batch = self.c_test[i * batch_size: (i + 1) * batch_size]\n",
    "            elif kind == \"out\":\n",
    "                x_batch = self.x_test_out[i * batch_size: (i + 1) * batch_size]\n",
    "                c_batch = self.c_test_out[i * batch_size: (i + 1) * batch_size]\n",
    "            else:\n",
    "                raise ValueError('unknown kind', kind)\n",
    "\n",
    "            cur_pres = self.sess.run(z_pres, feed_dict={self.in_ph: x_batch})\n",
    "            num_detected = np.sum(np.rint(cur_pres), axis=1)\n",
    "            correct += np.sum(num_detected == c_batch)\n",
    "            num_detected_tot += np.sum(num_detected)\n",
    "        test_acc = correct / (num_batches * batch_size)\n",
    "        avg_obj = num_detected_tot / (num_batches * batch_size)\n",
    "        return test_acc, avg_obj\n",
    "    \n",
    "    \n",
    "def grid_images(images, ncol=8, figsize=(12, 8)):\n",
    "    nrow = int(numpy.ceil(float(images.shape[0]) / ncol))\n",
    "    RGB = (3 == images.shape[-1])\n",
    "    \n",
    "    if nrow > 1:\n",
    "        fig, ax = plt.subplots(ncols=ncol, nrows=nrow, figsize=figsize)\n",
    "        for i in range(images.shape[0]):\n",
    "            c,r = i % ncol, i // ncol\n",
    "            if RGB:\n",
    "                ax[r,c].imshow(images[i,...], vmin=0, vmax=1)\n",
    "            else:\n",
    "                ax[r,c].imshow(images[i,...], cmap='gray', vmin=0, vmax=1)\n",
    "                \n",
    "            ax[r,c].set_axis_off()\n",
    "    else:\n",
    "        fig, ax = plt.subplots(ncols=images.shape[0], nrows=1, figsize=figsize)\n",
    "        for i in range(images.shape[0]):\n",
    "            if RGB:\n",
    "                ax[i].imshow(images[i,...], vmin=0, vmax=1)\n",
    "            else:\n",
    "                ax[i].imshow(images[i,...,0], cmap='gray', vmin=0, vmax=1)\n",
    "            ax[i].set_axis_off()\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def sub_select_inference(mask, cur_values):\n",
    "    return {'z_where' : cur_values['z_where'][mask,...],\n",
    "            'z_pres' : cur_values['z_pres'][mask,...],\n",
    "            'bg_score' : cur_values['bg_score'][mask,...],\n",
    "            'y' : cur_values['y'][mask,...],\n",
    "            'obj_vis' : cur_values['obj_vis'][mask,...],\n",
    "            'bg_maps' : cur_values['bg_maps'][mask,...],\n",
    "            }\n",
    "\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = config.SupairConfig()\n",
    "conf.visual = False\n",
    "\n",
    "# data config\n",
    "conf.dataset = 'MNIST'  # select dataset from 'MNIST', 'sprites', 'omniglot'\n",
    "conf.patch_width = conf.patch_height = 28\n",
    "\n",
    "conf.noise = False  # add Gaussian noise\n",
    "conf.structured_noise = True  # add background grid\n",
    "conf.background_model = True  # use learned background model\n",
    "\n",
    "conf.num_steps = 6  # maximum number of digits\n",
    "conf.dataset = 'MNIST'  # select MNIST\n",
    "\n",
    "# learning config\n",
    "conf.load_params = False\n",
    "conf.save_params = True\n",
    "conf.batch_size = 64 # default is 256\n",
    "\n",
    "\n",
    "# ORIGINAL\n",
    "conf.train_file = '../processed_dataset/their_mnist_train.npz'\n",
    "conf.test_file = '../processed_dataset/their_mnist_test.npz'\n",
    "conf.out_test_file = '../processed_dataset/their_mnist_test.npz'\n",
    "conf.checkpoint_dir = 'checkpoints_original'\n",
    "conf.log_file = 'reproduce.csv'\n",
    "conf.dir_result = 'REPRODUCE'\n",
    "conf.min_obj_scale = 0.3  # bounds for width of bounding box relative to native width=28\n",
    "conf.max_obj_scale = 0.9  # bounds for width of bounding box relative to native width=28\n",
    "\n",
    "## EXTRAPOLATION NO GRID\n",
    "#conf.train_file = '../processed_dataset/mnist_train_80x80_n0_3_no_grid.npz'\n",
    "#conf.test_file = '../processed_dataset/mnist_test_80x80_n0_3_no_grid.npz'\n",
    "#conf.out_test_file = '../processed_dataset/mnist_test_80x80_n4_6_no_grid.npz'\n",
    "#conf.checkpoint_dir = 'checkpoints_no_grid'\n",
    "#conf.log_file = 'no_grid.csv'\n",
    "#conf.dir_result = 'EXTRAPOLATION_NO_GRID'\n",
    "#conf.min_obj_scale = 0.3  # bounds for width of bounding box relative to native width=28\n",
    "#conf.max_obj_scale = 0.9  # bounds for width of bounding box relative to native width=28\n",
    "    \n",
    "# EXTRAPOLATION WITH GRID\n",
    "#conf.train_file = '../processed_dataset/mnist_train_80x80_n0_3_with_grid.npz'\n",
    "#conf.test_file = '../processed_dataset/mnist_test_80x80_n0_3_with_grid.npz'\n",
    "#conf.out_test_file = '../processed_dataset/mnist_test_80x80_n4_6_with_grid.npz'\n",
    "#conf.checkpoint_dir = 'checkpoints_with_grid'\n",
    "#conf.log_file = 'with_grid.csv'\n",
    "#conf.dir_result = 'EXTRAPOLATION_WITH_GRID'\n",
    "#conf.min_obj_scale = 0.3  # bounds for width of bounding box relative to native width=28\n",
    "#conf.max_obj_scale = 0.9  # bounds for width of bounding box relative to native width=28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert their dataset in our format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x, counts), (x_test, c_test) = datasets.load_mnist(conf.scene_width, max_digits=2, path=conf.data_path)\n",
    "#\n",
    "#numpy.savez_compressed(\"their_mnist_train\", images=x, counts=counts)\n",
    "#numpy.savez_compressed(\"their_mnist_test\", images=x_test, counts=c_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, c_train), (x_test, c_test), (x_test_out, c_test_out)= load_dataset_from_file(conf.train_file,\n",
    "                                                                                       conf.test_file,\n",
    "                                                                                       conf.out_test_file)\n",
    "print(x_train.shape, x_test.shape, x_test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c_train[0:16])\n",
    "grid_images(x_train[0:16], figsize=(12,3))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "trainer = SupairTrainer(conf)\n",
    "trainer.run_training()\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = numpy.zeros(conf.batch_size, dtype=numpy.bool)\n",
    "mask[25:29]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_values_train = sub_select_inference(mask, trainer.sess.run(trainer.tensors_of_interest, feed_dict={trainer.in_ph: x_train[:conf.batch_size]}))\n",
    "cur_values_test = sub_select_inference(mask, trainer.sess.run(trainer.tensors_of_interest, feed_dict={trainer.in_ph: x_test[:conf.batch_size]}))\n",
    "cur_values_test_out = sub_select_inference(mask, trainer.sess.run(trainer.tensors_of_interest, feed_dict={trainer.in_ph: x_test_out[:conf.batch_size]}))\n",
    "\n",
    "img_train = x_train[:conf.batch_size][mask]\n",
    "img_test = x_test[:conf.batch_size][mask]\n",
    "img_test_out = x_test_out[:conf.batch_size][mask]\n",
    "\n",
    "label_train = c_train[:conf.batch_size][mask]\n",
    "label_test = c_test[:conf.batch_size][mask]\n",
    "label_test_out = c_test_out[:conf.batch_size][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obj_train = np.sum((cur_values_train['z_pres'] > 0.5), axis=-1)\n",
    "n_obj_test = np.sum((cur_values_test['z_pres'] > 0.5), axis=-1)\n",
    "n_obj_test_out = np.sum((cur_values_test_out['z_pres'] > 0.5), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = trainer.reconstruct_scenes(img_train, cur_values_train, draw_boxes=True)\n",
    "results_test = trainer.reconstruct_scenes(img_test, cur_values_test, draw_boxes=True)\n",
    "results_test_out = trainer.reconstruct_scenes(img_test_out, cur_values_test_out, draw_boxes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(cur_values_train, conf.dir_result+\"/cur_values_train\",)\n",
    "save_obj(cur_values_test, conf.dir_result+\"/cur_values_test\")\n",
    "save_obj(cur_values_test_out, conf.dir_result+\"/cur_values_test_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(img_train[:conf.batch_size], conf.dir_result+\"/imgs_train\",)\n",
    "save_obj(img_test[:conf.batch_size], conf.dir_result+\"/imgs_test\")\n",
    "save_obj(img_test_out[:conf.batch_size], conf.dir_result+\"/imgs_test_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_train)\n",
    "b = grid_images(img_train, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_in_train.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_obj_train)\n",
    "b = grid_images(results_train, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_out_train.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_test)\n",
    "b = grid_images(img_test, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_in_test.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_obj_test)\n",
    "b = grid_images(results_test, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_out_test.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_test_out)\n",
    "b = grid_images(img_test_out, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_in_extrapolation.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_values_test_out[\"z_pres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_obj_test_out)\n",
    "b = grid_images(results_test_out, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_out_extrapolation.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu90.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu90:m59"
  },
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
