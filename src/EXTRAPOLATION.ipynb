{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRAPOLATION sp-air \n",
    "Recall to select the myenv in the python kernel\n",
    "\"source activate myenv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.12 | packaged by conda-forge | (default, Dec  9 2020, 00:36:02) \n",
      "[GCC 9.3.0]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import copy\n",
    "import numpy\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.misc import imresize\n",
    "\n",
    "import config\n",
    "import model\n",
    "import rat_spn\n",
    "from visualize import draw_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_file(train_file, test_file, out_of_sample_test_file):\n",
    "    loaded_train = numpy.load(train_file)\n",
    "    loaded_test = numpy.load(test_file)\n",
    "    loaded_test_out = numpy.load(out_of_sample_test_file)\n",
    "    return (loaded_train['images'], \n",
    "            loaded_train['counts']), (loaded_test['images'], \n",
    "                                      loaded_test['counts']), (loaded_test_out['images'], \n",
    "                                                               loaded_test_out['counts'])\n",
    "\n",
    "class SpnReconstructor:\n",
    "    def __init__(self, spn):\n",
    "        self.spn = spn\n",
    "        self.input_ph = tf.placeholder(tf.float32, (1, spn.num_dims))\n",
    "        self.marginalized = tf.placeholder(tf.float32, (1, spn.num_dims))\n",
    "        self.spn_out = spn.forward(self.input_ph, self.marginalized)\n",
    "        self.max_idx_tensors = {}\n",
    "        for layer in spn.vector_list:\n",
    "            for vector in layer:\n",
    "                if isinstance(vector, rat_spn.SumVector):\n",
    "                    self.max_idx_tensors[vector.name] = vector.max_child_idx\n",
    "\n",
    "    def reconstruct(self, image, marginalized, sess, sample=False):\n",
    "        original_shape = image.shape\n",
    "        image = np.reshape(image, (1, -1))\n",
    "        marginalized = np.reshape(marginalized, (1, -1))\n",
    "        feed_dict = {self.input_ph: image, self.marginalized: marginalized}\n",
    "        max_idxs = sess.run(self.max_idx_tensors, feed_dict=feed_dict)\n",
    "        recon = self.spn.reconstruct(max_idxs, sess, sample)\n",
    "        recon = recon * (1 - marginalized)\n",
    "        recon = np.clip(recon, 0.0, 1.0)\n",
    "        return np.reshape(recon, original_shape)\n",
    "\n",
    "\n",
    "class SupairTrainer:\n",
    "    def __init__(self, conf):\n",
    "        \n",
    "        \n",
    "        # load data and add make sure that conf has the appropriate variables describing the dataset\n",
    "        bboxes = None\n",
    "        if conf.dataset == 'MNIST':\n",
    "            (x, counts), (x_test, c_test), (x_test_out, c_test_out) = load_dataset_from_file(conf.train_file,\n",
    "                                                                                             conf.test_file,\n",
    "                                                                                             conf.out_test_file)\n",
    "            conf.scene_width = x.shape[-3]\n",
    "            conf.scene_height = x.shape[-2]\n",
    "            conf.channels = x.shape[-1]\n",
    "        else:\n",
    "            raise ValueError('unknown dataset', conf.dataset)\n",
    "            \n",
    "        # shuffle the order\n",
    "        shuffle = numpy.random.permutation(x.shape[0])\n",
    "        self.x, self.counts = x[shuffle,...], counts[shuffle]\n",
    "        shuffle = numpy.random.permutation(x_test.shape[0])\n",
    "        self.x_test, self.c_test = x_test[shuffle,...], c_test[shuffle]\n",
    "        shuffle = numpy.random.permutation(x_test_out.shape[0])\n",
    "        self.x_test_out, self.c_test_out = x_test_out[shuffle,...], c_test_out[shuffle]\n",
    "            \n",
    "            \n",
    "        \n",
    "        self.conf = conf\n",
    "\n",
    "        # determine and create result dir\n",
    "        i = 1\n",
    "        log_path = conf.result_path + 'run0'\n",
    "        while os.path.exists(log_path):\n",
    "            log_path = '{}run{}'.format(conf.result_path, i)\n",
    "            i += 1\n",
    "        os.makedirs(log_path)\n",
    "        self.log_path = log_path\n",
    "\n",
    "        if not os.path.exists(conf.checkpoint_dir):\n",
    "            os.makedirs(conf.checkpoint_dir)\n",
    "\n",
    "        input_shape = [conf.batch_size, conf.scene_width, conf.scene_height, conf.channels]\n",
    "        # build model\n",
    "        with tf.device(conf.device):\n",
    "            self.mdl = model.Supair(conf)\n",
    "            self.in_ph = tf.placeholder(tf.float32, input_shape)\n",
    "            self.elbo = self.mdl.elbo(self.in_ph)\n",
    "\n",
    "            self.mdl.num_parameters()\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer()\n",
    "            self.train_op = self.optimizer.minimize(-1 * self.elbo)\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.saver = tf.train.Saver()\n",
    "        if self.conf.load_params:\n",
    "            resume_ckpt = os.path.join(self.conf.path_to_ckpt)\n",
    "            self.saver.restore(self.sess, resume_ckpt)\n",
    "        else:\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "            self.sess.run(tf.local_variables_initializer())\n",
    "\n",
    "        print('Built model')\n",
    "        self.obj_reconstructor = SpnReconstructor(self.mdl.obj_spn)\n",
    "        self.bg_reconstructor = SpnReconstructor(self.mdl.bg_spn)\n",
    "\n",
    "        tfgraph = tf.get_default_graph()\n",
    "        self.tensors_of_interest = {\n",
    "            'z_where': tfgraph.get_tensor_by_name('z_where:0'),\n",
    "            'z_pres': tfgraph.get_tensor_by_name('z_pres:0'),\n",
    "            'bg_score': tfgraph.get_tensor_by_name('bg_score:0'),\n",
    "            'y': tfgraph.get_tensor_by_name('y:0'),\n",
    "            'obj_vis': tfgraph.get_tensor_by_name('obj_vis:0'),\n",
    "            'bg_maps': tfgraph.get_tensor_by_name('bg_maps:0')\n",
    "        }\n",
    "\n",
    "    def log_and_print_progress(self, n_iter, acc, elbo, avg_obj, log_file, title):\n",
    "        print('{}, N_iter {}, Accuracy: {}, avg_obj: {}, elbo {}'.format(title, n_iter, acc, avg_obj, elbo))\n",
    "        log_file.write('{}, {}, {}, {}, {}\\n'.format(title, n_iter, acc, avg_obj, elbo))\n",
    "        log_file.flush()\n",
    "\n",
    "    def reconstruct_scenes(self, images, cur_values, draw_boxes=True):\n",
    "        num_detected = np.sum(np.rint(cur_values['z_pres']), axis=1).astype(np.int32)\n",
    "        results = []\n",
    "        for i in range(images.shape[0]):\n",
    "            n = int(num_detected[i])\n",
    "            y = cur_values['y'][i]\n",
    "            z_where = cur_values['z_where'][i]\n",
    "            obj_vis = cur_values['obj_vis'][i]\n",
    "            objects = [self.obj_reconstructor.reconstruct(y[k], 1 - obj_vis[k], self.sess)\n",
    "                       for k in range(n)]\n",
    "            bg_map = cur_values['bg_maps'][i, n]\n",
    "            bg = self.bg_reconstructor.reconstruct(images[i], 1 - bg_map, self.sess, sample=True)\n",
    "            \n",
    "            for j in range(n - 1, -1, -1):\n",
    "                col = int(z_where[j, 2])\n",
    "                row = int(z_where[j, 5])\n",
    "                w = int(z_where[j, 0] * self.conf.patch_width)\n",
    "                h = int(z_where[j, 4] * self.conf.patch_height)\n",
    "                \n",
    "                # check for pathological object dimensions; treat as not present\n",
    "                if h <= 0 or w <= 0 or row < 0 or col < 0 or row + h > 50 or col + w > 50:\n",
    "                    continue\n",
    "                obj = imresize(np.squeeze(objects[j]), (h, w)).astype(np.float32) / 255.0\n",
    "                bg[row:row + h, col:col + w, 0] = obj\n",
    "\n",
    "            results.append(bg)\n",
    "\n",
    "        results = np.stack(results, 0)\n",
    "        results = np.clip(results, 0.0, 1.0)\n",
    "        \n",
    "        # Now Add the bounding boxes\n",
    "        if draw_boxes:\n",
    "            boxes = draw_images(results[...,0], cur_values['z_where'], cur_values['z_pres'], window_size=self.conf.patch_width, text=None)\n",
    "            boxes = numpy.moveaxis(boxes, -3, -1) / 255.0\n",
    "            return boxes + (boxes==0)*results  # this should work b/c broadcasting\n",
    "        else:\n",
    "            return results\n",
    "            \n",
    "\n",
    "    def run_training(self):\n",
    "        batch_size = self.conf.batch_size\n",
    "        batches_per_epoch = self.x.shape[0] // batch_size\n",
    "        sess = self.sess\n",
    "\n",
    "        perf_log = open(self.conf.log_file, 'a')\n",
    "        \n",
    "        for n_iter in range(20000):\n",
    "            i = n_iter % batches_per_epoch            \n",
    "            batch = self.x[i * batch_size: (i + 1) * batch_size]\n",
    "            \n",
    "            # print(\"DEBUG ->\",n_iter, i, batch.shape)\n",
    "                 \n",
    "            _, cur_elbo, cur_values = sess.run([self.train_op, self.elbo, self.tensors_of_interest], feed_dict={self.in_ph: batch})\n",
    "\n",
    "            if (n_iter % 1000 ==0) and (n_iter > 0):\n",
    "                # save the model \n",
    "                ckpt_file = os.path.join(self.conf.checkpoint_dir, \"model_\"+str(n_iter)+\".ckpt\")\n",
    "                self.saver.save(sess, ckpt_file)\n",
    "                \n",
    "            if (n_iter % 100 == 0):\n",
    "                # train accuracy\n",
    "                num_detected = np.sum(np.rint(cur_values['z_pres']), axis=1).astype(np.int32)\n",
    "                batch_counts = self.counts[i * batch_size: (i + 1) * batch_size]\n",
    "                train_acc = np.mean(num_detected == batch_counts)\n",
    "                avg_obj = np.average(num_detected)\n",
    "                self.log_and_print_progress(n_iter, train_acc, cur_elbo, avg_obj, perf_log, title=\"train\")\n",
    "                    \n",
    "            if (n_iter % 100 == 0):\n",
    "                print(\"computing test acc\")\n",
    "                test_elbo = 0\n",
    "                test_acc, test_avg_obj = self.compute_test_acc(kind=\"in\")\n",
    "                self.log_and_print_progress(n_iter, test_acc, test_elbo, test_avg_obj, perf_log, title=\"test_in\")\n",
    "                test_acc, test_avg_obj = self.compute_test_acc(kind=\"out\")\n",
    "                self.log_and_print_progress(n_iter, test_acc, test_elbo, test_avg_obj, perf_log, title=\"test_out\")\n",
    "     \n",
    "        perf_log.close()\n",
    "\n",
    "\n",
    "    def compute_test_acc(self, kind):\n",
    "        batch_size = self.conf.batch_size\n",
    "        \n",
    "        if kind == \"in\":\n",
    "            num_batches = self.x_test.shape[0] // batch_size \n",
    "        elif kind == \"out\":\n",
    "            num_batches = self.x_test_out.shape[0] // batch_size \n",
    "        else:\n",
    "            raise ValueError('unknown kind', kind)\n",
    "            \n",
    "        z_pres = self.tensors_of_interest['z_pres']\n",
    "        correct, num_detected_tot = 0, 0\n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            if kind == \"in\":\n",
    "                x_batch = self.x_test[i * batch_size: (i + 1) * batch_size]\n",
    "                c_batch = self.c_test[i * batch_size: (i + 1) * batch_size]\n",
    "            elif kind == \"out\":\n",
    "                x_batch = self.x_test_out[i * batch_size: (i + 1) * batch_size]\n",
    "                c_batch = self.c_test_out[i * batch_size: (i + 1) * batch_size]\n",
    "            else:\n",
    "                raise ValueError('unknown kind', kind)\n",
    "\n",
    "            cur_pres = self.sess.run(z_pres, feed_dict={self.in_ph: x_batch})\n",
    "            num_detected = np.sum(np.rint(cur_pres), axis=1)\n",
    "            correct += np.sum(num_detected == c_batch)\n",
    "            num_detected_tot += np.sum(num_detected)\n",
    "        test_acc = correct / (num_batches * batch_size)\n",
    "        avg_obj = num_detected_tot / (num_batches * batch_size)\n",
    "        return test_acc, avg_obj\n",
    "    \n",
    "    \n",
    "def grid_images(images, ncol=8, figsize=(12, 8)):\n",
    "    nrow = int(numpy.ceil(float(images.shape[0]) / ncol))\n",
    "    RGB = (3 == images.shape[-1])\n",
    "    \n",
    "    if nrow > 1:\n",
    "        fig, ax = plt.subplots(ncols=ncol, nrows=nrow, figsize=figsize)\n",
    "        for i in range(images.shape[0]):\n",
    "            c,r = i % ncol, i // ncol\n",
    "            if RGB:\n",
    "                ax[r,c].imshow(images[i,...], vmin=0, vmax=1)\n",
    "            else:\n",
    "                ax[r,c].imshow(images[i,...], cmap='gray', vmin=0, vmax=1)\n",
    "                \n",
    "            ax[r,c].set_axis_off()\n",
    "    else:\n",
    "        fig, ax = plt.subplots(ncols=images.shape[0], nrows=1, figsize=figsize)\n",
    "        for i in range(images.shape[0]):\n",
    "            if RGB:\n",
    "                ax[i].imshow(images[i,...], vmin=0, vmax=1)\n",
    "            else:\n",
    "                ax[i].imshow(images[i,...,0], cmap='gray', vmin=0, vmax=1)\n",
    "            ax[i].set_axis_off()\n",
    "        \n",
    "    fig.tight_layout()\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "\n",
    "def sub_select_inference(mask, cur_values):\n",
    "    return {'z_where' : cur_values['z_where'][mask,...],\n",
    "            'z_pres' : cur_values['z_pres'][mask,...],\n",
    "            'bg_score' : cur_values['bg_score'][mask,...],\n",
    "            'y' : cur_values['y'][mask,...],\n",
    "            'obj_vis' : cur_values['obj_vis'][mask,...],\n",
    "            'bg_maps' : cur_values['bg_maps'][mask,...],\n",
    "            }\n",
    "\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = config.SupairConfig()\n",
    "conf.visual = False\n",
    "\n",
    "# data config\n",
    "conf.dataset = 'MNIST'  # select dataset from 'MNIST', 'sprites', 'omniglot'\n",
    "conf.patch_width = conf.patch_height = 28\n",
    "\n",
    "conf.noise = False  # add Gaussian noise\n",
    "conf.structured_noise = True  # add background grid\n",
    "conf.background_model = True  # use learned background model\n",
    "\n",
    "conf.num_steps = 6  # maximum number of digits\n",
    "conf.dataset = 'MNIST'  # select MNIST\n",
    "\n",
    "# learning config\n",
    "conf.load_params = False\n",
    "conf.save_params = True\n",
    "conf.batch_size = 64 # default is 256\n",
    "\n",
    "\n",
    "# ORIGINAL\n",
    "conf.train_file = '../processed_dataset/their_mnist_train.npz'\n",
    "conf.test_file = '../processed_dataset/their_mnist_test.npz'\n",
    "conf.out_test_file = '../processed_dataset/their_mnist_test.npz'\n",
    "conf.checkpoint_dir = 'checkpoints_original'\n",
    "conf.log_file = 'reproduce.csv'\n",
    "conf.dir_result = 'REPRODUCE'\n",
    "conf.min_obj_scale = 0.3  # bounds for width of bounding box relative to native width=28\n",
    "conf.max_obj_scale = 0.9  # bounds for width of bounding box relative to native width=28\n",
    "\n",
    "## EXTRAPOLATION NO GRID\n",
    "#conf.train_file = '../processed_dataset/mnist_train_80x80_n0_3_no_grid.npz'\n",
    "#conf.test_file = '../processed_dataset/mnist_test_80x80_n0_3_no_grid.npz'\n",
    "#conf.out_test_file = '../processed_dataset/mnist_test_80x80_n4_6_no_grid.npz'\n",
    "#conf.checkpoint_dir = 'checkpoints_no_grid'\n",
    "#conf.log_file = 'no_grid.csv'\n",
    "#conf.dir_result = 'EXTRAPOLATION_NO_GRID'\n",
    "#conf.min_obj_scale = 0.3  # bounds for width of bounding box relative to native width=28\n",
    "#conf.max_obj_scale = 0.9  # bounds for width of bounding box relative to native width=28\n",
    "    \n",
    "# EXTRAPOLATION WITH GRID\n",
    "#conf.train_file = '../processed_dataset/mnist_train_80x80_n0_3_with_grid.npz'\n",
    "#conf.test_file = '../processed_dataset/mnist_test_80x80_n0_3_with_grid.npz'\n",
    "#conf.out_test_file = '../processed_dataset/mnist_test_80x80_n4_6_with_grid.npz'\n",
    "#conf.checkpoint_dir = 'checkpoints_with_grid'\n",
    "#conf.log_file = 'with_grid.csv'\n",
    "#conf.dir_result = 'EXTRAPOLATION_WITH_GRID'\n",
    "#conf.min_obj_scale = 0.3  # bounds for width of bounding box relative to native width=28\n",
    "#conf.max_obj_scale = 0.9  # bounds for width of bounding box relative to native width=28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert their dataset in our format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x, counts), (x_test, c_test) = datasets.load_mnist(conf.scene_width, max_digits=2, path=conf.data_path)\n",
    "#\n",
    "#numpy.savez_compressed(\"their_mnist_train\", images=x, counts=counts)\n",
    "#numpy.savez_compressed(\"their_mnist_test\", images=x_test, counts=c_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 50, 50, 1) (10000, 50, 50, 1) (10000, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, c_train), (x_test, c_test), (x_test_out, c_test_out)= load_dataset_from_file(conf.train_file,\n",
    "                                                                                       conf.test_file,\n",
    "                                                                                       conf.out_test_file)\n",
    "print(x_train.shape, x_test.shape, x_test_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2 2 0 0 2 1 2 2 2 2 0 2 1 0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3a3577e34ed3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgrid_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-892c2b73cc29>\u001b[0m in \u001b[0;36mgrid_images\u001b[0;34m(images, ncol, figsize)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis_off\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/myenv/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1783\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1785\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/envs/myenv/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5470\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5472\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5473\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/myenv/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    644\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    645\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(c_train[0:16])\n",
    "grid_images(x_train[0:16], figsize=(12,3))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "trainer = SupairTrainer(conf)\n",
    "trainer.run_training()\n",
    "#tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the model after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = numpy.zeros(conf.batch_size, dtype=numpy.bool)\n",
    "mask[25:29]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_values_train = sub_select_inference(mask, trainer.sess.run(trainer.tensors_of_interest, feed_dict={trainer.in_ph: x_train[:conf.batch_size]}))\n",
    "cur_values_test = sub_select_inference(mask, trainer.sess.run(trainer.tensors_of_interest, feed_dict={trainer.in_ph: x_test[:conf.batch_size]}))\n",
    "cur_values_test_out = sub_select_inference(mask, trainer.sess.run(trainer.tensors_of_interest, feed_dict={trainer.in_ph: x_test_out[:conf.batch_size]}))\n",
    "\n",
    "img_train = x_train[:conf.batch_size][mask]\n",
    "img_test = x_test[:conf.batch_size][mask]\n",
    "img_test_out = x_test_out[:conf.batch_size][mask]\n",
    "\n",
    "label_train = c_train[:conf.batch_size][mask]\n",
    "label_test = c_test[:conf.batch_size][mask]\n",
    "label_test_out = c_test_out[:conf.batch_size][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_obj_train = np.sum((cur_values_train['z_pres'] > 0.5), axis=-1)\n",
    "n_obj_test = np.sum((cur_values_test['z_pres'] > 0.5), axis=-1)\n",
    "n_obj_test_out = np.sum((cur_values_test_out['z_pres'] > 0.5), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = trainer.reconstruct_scenes(img_train, cur_values_train, draw_boxes=True)\n",
    "results_test = trainer.reconstruct_scenes(img_test, cur_values_test, draw_boxes=True)\n",
    "results_test_out = trainer.reconstruct_scenes(img_test_out, cur_values_test_out, draw_boxes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(cur_values_train, conf.dir_result+\"/cur_values_train\",)\n",
    "save_obj(cur_values_test, conf.dir_result+\"/cur_values_test\")\n",
    "save_obj(cur_values_test_out, conf.dir_result+\"/cur_values_test_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(img_train[:conf.batch_size], conf.dir_result+\"/imgs_train\",)\n",
    "save_obj(img_test[:conf.batch_size], conf.dir_result+\"/imgs_test\")\n",
    "save_obj(img_test_out[:conf.batch_size], conf.dir_result+\"/imgs_test_out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_train)\n",
    "b = grid_images(img_train, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_in_train.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_obj_train)\n",
    "b = grid_images(results_train, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_out_train.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_test)\n",
    "b = grid_images(img_test, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_in_test.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_obj_test)\n",
    "b = grid_images(results_test, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_out_test.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_test_out)\n",
    "b = grid_images(img_test_out, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_in_extrapolation.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur_values_test_out[\"z_pres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_obj_test_out)\n",
    "b = grid_images(results_test_out, figsize=(12,3))\n",
    "b.savefig(conf.dir_result+\"/img_out_extrapolation.pdf\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu90.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu90:m59"
  },
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
